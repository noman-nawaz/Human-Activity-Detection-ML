{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51773fb",
   "metadata": {},
   "source": [
    "## Activity Recognition for Sensor-based Data\n",
    "\n",
    "### Group Members:\n",
    "- #### BCSF20M032\n",
    "- #### BCSF20M042\n",
    "- #### BCSF20M044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3248c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693c4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eed30b",
   "metadata": {},
   "source": [
    "- #### Reading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77511bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accelerometer = np.load(\"trainAccelerometer.npy\")\n",
    "train_Gravity = np.load(\"trainGravity.npy\")\n",
    "train_Gyroscope = np.load(\"trainGyroscope.npy\")\n",
    "train_JinsAccelerometer = np.load(\"trainJinsAccelerometer.npy\")\n",
    "train_JinsGyroscope = np.load(\"trainJinsGyroscope.npy\")\n",
    "train_LinearAcceleration = np.load(\"trainLinearAcceleration.npy\")\n",
    "train_Magnetometer = np.load(\"trainMagnetometer.npy\")\n",
    "train_MSAccelerometer = np.load(\"trainMSAccelerometer.npy\")\n",
    "train_MSGyroscope = np.load(\"trainMSGyroscope.npy\")\n",
    "train_Labels = np.load(\"trainLabels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a13196",
   "metadata": {},
   "source": [
    "- #### Reading Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ba9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accelerometer = np.load(\"testAccelerometer.npy\")\n",
    "test_Gravity = np.load(\"testGravity.npy\")\n",
    "test_Gyroscope = np.load(\"testGyroscope.npy\")\n",
    "test_JinsAccelerometer = np.load(\"testJinsAccelerometer.npy\")\n",
    "test_JinsGyroscope = np.load(\"testJinsGyroscope.npy\")\n",
    "test_LinearAcceleration = np.load(\"testLinearAcceleration.npy\")\n",
    "test_Magnetometer = np.load(\"testMagnetometer.npy\")\n",
    "test_MSAccelerometer = np.load(\"testMSAccelerometer.npy\")\n",
    "test_MSGyroscope = np.load(\"testMSGyroscope.npy\")\n",
    "test_Labels = np.load(\"testLabels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802ccbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2284, 800, 3)\n",
      "(2284, 800, 3)\n",
      "(2284, 800, 3)\n",
      "(2284, 80, 3)\n",
      "(2284, 80, 3)\n",
      "(2284, 800, 3)\n",
      "(2284, 200, 3)\n",
      "(2284, 268, 3)\n",
      "(2284, 268, 3)\n",
      "(2284,)\n",
      "(2288, 800, 3)\n",
      "(2288, 800, 3)\n",
      "(2288, 800, 3)\n",
      "(2288, 80, 3)\n",
      "(2288, 80, 3)\n",
      "(2288, 800, 3)\n",
      "(2288, 200, 3)\n",
      "(2288, 268, 3)\n",
      "(2288, 268, 3)\n",
      "(2288,)\n"
     ]
    }
   ],
   "source": [
    "print(train_Accelerometer.shape)\n",
    "print(train_Gravity.shape)\n",
    "print(train_Gyroscope.shape)\n",
    "print(train_JinsAccelerometer.shape)\n",
    "print(train_JinsGyroscope.shape)\n",
    "print(train_LinearAcceleration.shape)\n",
    "print(train_Magnetometer.shape)\n",
    "print(train_MSAccelerometer.shape)\n",
    "print(train_MSGyroscope.shape)\n",
    "print(train_Labels.shape)\n",
    "\n",
    "print(test_Accelerometer.shape)\n",
    "print(test_Gravity.shape)\n",
    "print(test_Gyroscope.shape)\n",
    "print(test_JinsAccelerometer.shape)\n",
    "print(test_JinsGyroscope.shape)\n",
    "print(test_LinearAcceleration.shape)\n",
    "print(test_Magnetometer.shape)\n",
    "print(test_MSAccelerometer.shape)\n",
    "print(test_MSGyroscope.shape)\n",
    "print(test_Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234a304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556a936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Examples:  2284\n",
      "Testing Examples:  2288\n"
     ]
    }
   ],
   "source": [
    "# Number of Training and Testing Examples\n",
    "m_train = np.shape(train_Labels)[0]\n",
    "m_test = np.shape(test_Labels)[0]\n",
    "print(\"Training Examples: \", m_train)\n",
    "print(\"Testing Examples: \", m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22336c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2284, 90, 3)\n",
      "(2288, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "# 3D array to store features\n",
    "total_features = 10\n",
    "train_features = np.zeros((m_train, 9*total_features, 3))\n",
    "test_features = np.zeros((m_test, 9*total_features, 3))\n",
    "\n",
    "print(np.shape(train_features))\n",
    "print(np.shape(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2300e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6384c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean \n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fcca31",
   "metadata": {},
   "source": [
    "- #### Extracting & Learning Meaningful Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b94ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 features (mean, median, max, min, sum, range, std, var, percentile 25, percentile 75 )\n",
    "\n",
    "# For Training DataSet\n",
    "num_sensors = 9\n",
    "for i in range(num_sensors):\n",
    "    sensor = None\n",
    "    if i == 0:\n",
    "        sensor = train_Accelerometer\n",
    "    elif i == 1:\n",
    "        sensor = train_Gravity\n",
    "    elif i == 2:\n",
    "        sensor = train_Gyroscope\n",
    "    elif i == 3:\n",
    "        sensor = train_JinsAccelerometer\n",
    "    elif i == 4:\n",
    "        sensor = train_JinsGyroscope\n",
    "    elif i == 5:\n",
    "        sensor = train_LinearAcceleration\n",
    "    elif i == 6:\n",
    "        sensor = train_Magnetometer\n",
    "    elif i == 7:\n",
    "        sensor = train_MSAccelerometer\n",
    "    elif i == 8:\n",
    "        sensor = train_MSGyroscope\n",
    "\n",
    "    train_features[:,i * total_features,:] = np.mean(sensor, axis=1)\n",
    "    train_features[:,i * total_features + 1,:] = np.median(sensor, axis=1)\n",
    "    train_features[:,i * total_features + 2,:] = np.max(sensor, axis=1)\n",
    "    train_features[:,i * total_features + 3,:] = np.min(sensor, axis=1)\n",
    "    train_features[:,i * total_features + 4,:] = np.sum(sensor, axis=1)\n",
    "    train_features[:,i * total_features + 5,:] = np.max(sensor, axis=1) - np.min(sensor, axis=1)\n",
    "    train_features[:,i * total_features + 6,:] = np.std(sensor, axis=1)\n",
    "    train_features[:,i * total_features + 7,:] = np.var(sensor, axis=1)\n",
    "    train_features[:,i * total_features + 8,:] = np.percentile(sensor, 25, axis=1)\n",
    "    train_features[:,i * total_features + 9,:] = np.percentile(sensor, 75, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e69f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Testing DataSet, Extracting Features\n",
    "\n",
    "for i in range(num_sensors):\n",
    "    sensor = None\n",
    "    if i == 0:\n",
    "        sensor = test_Accelerometer\n",
    "    elif i == 1:\n",
    "        sensor = test_Gravity\n",
    "    elif i == 2:\n",
    "        sensor = test_Gyroscope\n",
    "    elif i == 3:\n",
    "        sensor = test_JinsAccelerometer\n",
    "    elif i == 4:\n",
    "        sensor = test_JinsGyroscope\n",
    "    elif i == 5:\n",
    "        sensor = test_LinearAcceleration\n",
    "    elif i == 6:\n",
    "        sensor = test_Magnetometer\n",
    "    elif i == 7:\n",
    "        sensor = test_MSAccelerometer\n",
    "    elif i == 8:\n",
    "        sensor = test_MSGyroscope\n",
    "\n",
    "    test_features[:, i * total_features, :] = np.mean(sensor, axis=1)\n",
    "    test_features[:, i * total_features + 1, :] = np.median(sensor, axis=1)\n",
    "    test_features[:, i * total_features + 2, :] = np.max(sensor, axis=1)\n",
    "    test_features[:, i * total_features + 3, :] = np.min(sensor, axis=1)\n",
    "    test_features[:, i * total_features + 4, :] = np.sum(sensor, axis=1)\n",
    "    test_features[:, i * total_features + 5, :] = np.max(sensor, axis=1) - np.min(sensor, axis=1)\n",
    "    test_features[:, i * total_features + 6, :] = np.std(sensor, axis=1)\n",
    "    test_features[:, i * total_features + 7, :] = np.var(sensor, axis=1)\n",
    "    test_features[:, i * total_features + 8, :] = np.percentile(sensor, 25, axis=1)\n",
    "    test_features[:, i * total_features + 9, :] = np.percentile(sensor, 75, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "800e2e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2284, 90, 3)\n",
      "(2284, 270)\n",
      "(2288, 90, 3)\n",
      "(2288, 270)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping to 2D\n",
    "print(np.shape(train_features))\n",
    "train_features_reshaped = np.reshape(train_features, (np.shape(train_features)[0], np.shape(train_features)[1]*np.shape(train_features)[2] ))\n",
    "print(np.shape(train_features_reshaped))\n",
    "\n",
    "print(np.shape(test_features))\n",
    "test_features_reshaped = np.reshape(test_features, (np.shape(test_features)[0], np.shape(test_features)[1]*np.shape(test_features)[2] ))\n",
    "print(np.shape(test_features_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181a1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ee421",
   "metadata": {},
   "source": [
    "- #### Multi-class Classification using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f03f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier = SVC(C=1.0, kernel='linear')  \n",
    "classfier.fit(train_features_reshaped,train_Labels)\n",
    "predicted_Labels = classfier.predict(test_features_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6a4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "928af84a",
   "metadata": {},
   "source": [
    "- #### Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5209aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-score = 0.3936651917217737\n",
      "Test Recall = 39.6\n",
      "Test accuracy = 39.47\n",
      "Weighted F1-score = 0.3935419108319004\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0  1 ...  0  0  1]\n",
      " [ 0 33  2 ...  1  0  0]\n",
      " [ 0  7  6 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  4 ...  8  0  0]\n",
      " [ 0  0  0 ...  0 20  0]\n",
      " [ 1  1  1 ...  2  0 14]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_Labels,predicted_Labels)\n",
    "recall = recall_score(test_Labels,predicted_Labels,average='macro')\n",
    "weightedF1 = f1_score(test_Labels,predicted_Labels,average='weighted')\n",
    "averageF1 = f1_score(test_Labels,predicted_Labels,average='macro')\n",
    "conf_matrix = confusion_matrix(test_Labels,predicted_Labels)\n",
    "\n",
    "print('Average F1-score =' , averageF1)\n",
    "print('Test Recall =' ,round((recall*100),2))\n",
    "print('Test accuracy =' , round((accuracy*100),2))\n",
    "print('Weighted F1-score =', (weightedF1))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38f2f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582caab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
